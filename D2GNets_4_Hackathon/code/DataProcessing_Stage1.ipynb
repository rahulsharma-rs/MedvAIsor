{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ztGTnLcUmkV5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pubchempy in /data/user/home/rsharma3/.local/lib/python3.9/site-packages (1.0.4)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pubchempy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user/rsharma3/nbotw/Project-D2GNETs/Code\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, os.path.abspath(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, QuantileTransformer, PowerTransformer,Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Fpc_NOWkFX-K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pubchempy as pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "sio = sys.stderr = StringIO()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmzBmI-oFyOq",
    "tags": []
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Line Gene Expression data from COSMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../D2GNets/data/AllGeneExpression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug REsponse and Drug Information data from GDSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YdxBUkEaGXrL"
   },
   "outputs": [],
   "source": [
    "df_GDSC = pd.read_csv('../../D2GNets/data/GDSC2_fitted_dose_response_25Feb20_3.csv')\n",
    "df_GDSC_DrugInfo = pd.read_csv('../../D2GNets/data/Drug_Desciption_GDSC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Drug Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFX3OOaSm1nX"
   },
   "outputs": [],
   "source": [
    "##incomment is you want to extract features from Pubchem\n",
    "# require #!pip install pubchempy\n",
    "'''\n",
    "lst = []\n",
    "\n",
    "ctr =0\n",
    "for x in df_GDSC_DrugInfo['drug_name'].unique().tolist():\n",
    "  c = pcp.get_compounds(x, 'name')\n",
    "  \n",
    "  if len(c) != 0:\n",
    "    tlst = []\n",
    "    tlst.append(x)\n",
    "    tlst.append(int(c[0].cid))\n",
    "    tlst.append(c[0].isomeric_smiles)\n",
    "    lst.append(tlst)\n",
    "  else:\n",
    "    ctr += 1\n",
    "    tlst = []\n",
    "    tlst.append(x)\n",
    "    tlst.append(None)\n",
    "    tlst.append(None)\n",
    "    lst.append(tlst)\n",
    "\n",
    "df = pd.DataFrame(lst, columns=['DRUG_NAME','PUBCHEM_ID','SMILES'])\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.isna().sum()\n",
    "\n",
    "df.to_csv('../../D2GNets/data/SMILES_FeatureEngineered.csv',index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NLP-based Feature Extraction from Drug SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('../../D2GNets/data/SMILES_FeatureEngineered.csv')\n",
    "df = df[['DRUG_NAME', 'PUBCHEM_ID', 'SMILES']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1x = pd.read_csv('../../D2GNets/data/Drugs_for_repurposing.csv')\n",
    "df_1x.rename(columns={'Drug':'DRUG_NAME','Cancer Type':'TCGA_DESC'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
    "def getKmers(sequence, size=6):\n",
    "  if sequence!=None:\n",
    "    lst =[]\n",
    "    X =None\n",
    "    for i in [1]:\n",
    "        for x in range(len(sequence) - i + 1):\n",
    "            try:\n",
    "                \n",
    "                X=Chem.MolFromSmiles(sequence[x:x+i])\n",
    "                sio = sys.stderr = StringIO()\n",
    "            except SyntaxError:\n",
    "                pass\n",
    "            if X is None:\n",
    "                continue\n",
    "            else:\n",
    "                lst.append(sequence[x:x+i])\n",
    "    return lst\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting single character-based legitimate molecule\n",
    "df['WORDS'] = df.apply(lambda x: getKmers(x['SMILES']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1x['WORDS'] = df_1x.apply(lambda x: getKmers(x['SMILES']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mols = [] # all legit single character molecule for all drug SMILES\n",
    "for x in list(df['WORDS']):\n",
    "    mols = mols + x\n",
    "    \n",
    "setx = list(set(mols)) # Unique Single Character Molecule set\n",
    "molName = [f'Mol{i}' for i in range(1,len(setx)+1)] # aliases for all single character Molecules\n",
    "molDict = {} # Dictionary to map the Single Character Molecule to their respective aliases\n",
    "\n",
    "ctr=1\n",
    "for i in setx:\n",
    "    molDict.update({i:f'Mol{ctr}'})\n",
    "    ctr+=1   \n",
    "mol = pd.DataFrame(np.asarray([setx,molName]).T,columns=['Molecule','tokenName'])\n",
    "mol.to_csv('../../D2GNets/data/Molecule_token_map.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapWords(lst=None):\n",
    "    if lst!=None:\n",
    "        tlst = []\n",
    "        for x in lst:\n",
    "            tlst.append(molDict[x])\n",
    "        return tlst\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "yPp4KCAKqt_L"
   },
   "outputs": [],
   "source": [
    "# words based on sequence of aliases of the drug SMILE \n",
    "df['WordMap']=df.apply(lambda x: mapWords(x['WORDS']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1x['WordMap']=df_1x.apply(lambda x: mapWords(x['WORDS']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_texts = list(df['WordMap']) # all aliases for all drug SMILES\n",
    "for item in range(len(df_texts)):\n",
    "    df_texts[item] = ' '.join(df_texts[item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts1= list(df_1x['WordMap']) # all aliases for all drug SMILES\n",
    "for item in range(len(df_texts1)):\n",
    "    df_texts1[item] = ' '.join(df_texts1[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "BGLHJs2trhGC"
   },
   "outputs": [],
   "source": [
    "n_gram_list = [1,2,3,4,5,6,7,8]\n",
    "# Creating the Bag of Words model using CountVectorizer()\n",
    "# This is equivalent to k-mer counting\n",
    "# The n-gram size of 4 was previously determined by testing\n",
    "for ind in n_gram_list:  #looping to create 8 type of n-gram vectors\n",
    "    #feature extraction based on Counts\n",
    "    cv = CountVectorizer(ngram_range=(ind,ind))\n",
    "    X = cv.fit_transform(df_texts)\n",
    "    X1 = cv.transform(df_texts1)\n",
    "    #Conveting the extracted features to thier term frequencies\n",
    "    tf_transformer = TfidfTransformer(use_idf=False).fit(X)\n",
    "    X = tf_transformer.transform(X)\n",
    "    X1 = tf_transformer.transform(X1)\n",
    "    count_vect_df = pd.DataFrame(X.todense(), columns=cv.get_feature_names())\n",
    "    count_vect_df1 = pd.DataFrame(X1.todense(), columns=cv.get_feature_names())\n",
    "    if ind ==1:\n",
    "        dff = pd.concat([df.reset_index(), count_vect_df], axis =1, ignore_index= False)\n",
    "        dff_1x = pd.concat([df_1x.reset_index(), count_vect_df1], axis =1, ignore_index= False)\n",
    "    else:\n",
    "        dff = pd.concat([dff, count_vect_df], axis =1, ignore_index= False)\n",
    "        dff_1x = pd.concat([dff_1x, count_vect_df1], axis =1, ignore_index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "fxUvDiJpsZIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of drug selected: 173\n",
      "number of features created: 2992\n"
     ]
    }
   ],
   "source": [
    "print('number of drug selected: %d'%dff.shape[0])\n",
    "print('number of features created: %d'%dff.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "CLMaYlEWX75l"
   },
   "outputs": [],
   "source": [
    "#saving the dataFrame for future reference\n",
    "dff.to_csv('../../D2GNets/data/SMILES_FeatureEngineered_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_1x.to_csv('../../D2GNets/data/SMILES_FeatureEngineered_Repurposing_drugs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mol1', 'mol2', 'mol3', 'mol4', 'mol5', 'mol6', 'mol7', 'mol8',\n",
       "       'mol1 mol1', 'mol1 mol2',\n",
       "       ...\n",
       "       'mol6 mol6 mol1 mol6 mol6 mol1 mol1 mol1',\n",
       "       'mol6 mol6 mol1 mol6 mol6 mol1 mol2 mol1',\n",
       "       'mol6 mol6 mol2 mol1 mol1 mol1 mol5 mol2',\n",
       "       'mol6 mol6 mol6 mol1 mol1 mol1 mol1 mol1',\n",
       "       'mol6 mol6 mol6 mol1 mol1 mol1 mol6 mol1',\n",
       "       'mol6 mol8 mol2 mol2 mol1 mol6 mol1 mol1',\n",
       "       'mol7 mol4 mol1 mol2 mol6 mol1 mol2 mol6',\n",
       "       'mol7 mol4 mol6 mol1 mol1 mol1 mol1 mol1',\n",
       "       'mol8 mol2 mol2 mol1 mol6 mol1 mol1 mol1',\n",
       "       'mol8 mol2 mol2 mol2 mol8 mol2 mol2 mol2'],\n",
       "      dtype='object', length=2986)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff_1x.columns[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-transforamtion of each feature of NLP-extracted drug features\n",
    "max_abs_scaler = StandardScaler()\n",
    "d1_1 = max_abs_scaler.fit_transform(dff[dff.columns[6:]])\n",
    "d1 = pd.DataFrame(d1_1,columns=dff.columns[6:].to_list())\n",
    "dff1 = pd.concat([dff[dff.columns[:6]],d1],axis=1)\n",
    "#dff1= dff.copy(deep=True)\n",
    "\n",
    "d1_1 = max_abs_scaler.fit_transform(dff_1x[dff_1x.columns[9:]])\n",
    "d1 = pd.DataFrame(d1_1,columns=dff_1x.columns[9:].to_list())\n",
    "dff1_1x = pd.concat([dff_1x[dff_1x.columns[:9]],d1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the intemediate dataframe for future reference\n",
    "dff1.to_csv('../../D2GNets/data/SMILES_FeatureEngineered_new_scaled.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff1_1x.to_csv('../../D2GNets/data/SMILES_FeatureEngineered_new_scaled_Repurposing_drugs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the names of the drug features\n",
    "dff1[dff.columns[6:]][:0].to_csv('../../D2GNets/data/moleculeNames_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extracting One-Hot coded Disease Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(list(df_GDSC['TCGA_DESC'].unique()))\n",
    "s.dropna(inplace=True)\n",
    "s1=pd.get_dummies(s)\n",
    "disease = pd.concat([s,s1],axis=1)\n",
    "disease.rename(columns={0:'TCGA_DESC'}, inplace=True)\n",
    "disease[disease.columns[1:]][:0].to_csv('../../D2GNets/data/diseaseNames.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the GDSC Dataframe with Disease Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1x = pd.merge(dff1_1x,disease, on=['TCGA_DESC'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(df_GDSC,disease, on=['TCGA_DESC'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the GDSC Dataframe with Disease Features to Drug Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "XP2wVYvwmWqS"
   },
   "outputs": [],
   "source": [
    "df1 = pd.merge(df1,dff1, on=['DRUG_NAME'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary columns\n",
    "df1.drop(columns=['DATASET', 'NLME_RESULT_ID', 'NLME_CURVE_ID','PUTATIVE_TARGET', 'CELL_LINE_NAME', 'SANGER_MODEL_ID',\n",
    "                         'PATHWAY_NAME', 'COMPANY_ID','WEBRELEASE', 'MIN_CONC', 'MAX_CONC','SMILES', 'WORDS', 'AUC', 'RMSE',\n",
    "                         'Z_SCORE', 'index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all rows with null values from the remaining data\n",
    "df1.drop(index=df1[df1.isna().any(axis=1)].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the merged DataFrame of Drug Respnse and Feature Engineered drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "FFk5kTRIo3Mc"
   },
   "outputs": [],
   "source": [
    "\n",
    "df1.to_csv('../../D2GNets/data/GDSC_Drug_Feature_Engineered_new_scaled.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating Drug and Disease data to Gene Expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataPrep(ExpName, GE_df,  Drug_df):\n",
    "    GE_df.dropna(inplace=True)\n",
    "\n",
    "    Drug_df.rename(columns={'COSMIC_ID':'SAMPLE_ID'},inplace=True)\n",
    "    Drug_df_GBM = Drug_df[Drug_df['TCGA_DESC']=='GBM'].copy(deep=True)\n",
    "\n",
    "    Drug_df.drop(Drug_df_GBM.index,inplace=True)\n",
    "    panCancer_train_df = pd.merge(Drug_df,GE_df, on=['SAMPLE_ID'], how='left')\n",
    "    GBM_train_df = pd.merge(Drug_df_GBM,GE_df, on=['SAMPLE_ID'], how='left')\n",
    "    \n",
    "    Drug_df= None\n",
    "    GE_df = None\n",
    "    Drug_df_GBM = None\n",
    "    GBM_known_drugs_test_df = None\n",
    "\n",
    "    panCancer_train_df.to_csv(f'../../D2GNets/data/panCancer_train_{ExpName}_df.csv',index=False)\n",
    "    panCancer_train_df=None\n",
    "\n",
    "    GBM_train_df.dropna(inplace=True)\n",
    "    GBM_train_df.to_csv(f'../../D2GNets/data/GBM_train_{ExpName}_df.csv',index=False)\n",
    "    GBM_train_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "GE_df = data\n",
    "Drug_df = df1\n",
    "censusGN = pd.read_csv('../../D2GNets/data/Census_allFri_May_6_15_00_18_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledged-based Feature Engineering. Selecting 657 genes from 16248 COSMIC Gene Set based on Cancer Gene Census Gene lest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = list(set(GE_df.columns).intersection(set(censusGN['Gene Symbol'].values)))\n",
    "GE_df = GE_df[['SAMPLE_ID']+X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPrep('CGC_657_DR_Drug_features_new', GE_df, Drug_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldf = pd.DataFrame(columns=X_cols)\n",
    "coldf.to_csv('../../D2GNets/data/657_Gene_name.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GBM_samples = pd.DataFrame()\n",
    "df_GBM_samples['SAMPLE_ID'] = (df_GDSC[df_GDSC['TCGA_DESC']=='GBM'])['COSMIC_ID'].unique()\n",
    "df_GBM_samples['TCGA_DESC'] = 'GBM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1x_1 =[]\n",
    "for i in (df_GDSC[df_GDSC['TCGA_DESC']=='GBM'])['COSMIC_ID'].unique():\n",
    "    temp = df1_1x.copy(deep=True)\n",
    "    temp['SAMPLE_ID']= i\n",
    "    df1_1x_1.append(temp)\n",
    "df1_1x_1 = pd.concat(df1_1x_1,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SAMPLE_ID', 'CBLB', 'NUP214', 'FCGR2B', 'FLNA', 'SNX29', 'LYN', 'SS18',\n",
       "       'TNC', 'PRKAR1A',\n",
       "       ...\n",
       "       'IL7R', 'LHFPL6', 'TAL1', 'ABL2', 'ANK1', 'MN1', 'CASP9', 'CYLD',\n",
       "       'ROBO2', 'ATP1A1'],\n",
       "      dtype='object', length=658)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GE_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "repurpose_FE_Data = pd.merge(df1_1x_1,GE_df,on=['SAMPLE_ID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "repurpose_FE_Data.to_csv('../../D2GNets/data/Repurposing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                0\n",
       "DRUG_NAME                            0\n",
       "Drug type                            0\n",
       "TCGA_DESC                            0\n",
       "The number of associated datasets    0\n",
       "                                    ..\n",
       "MN1                                  0\n",
       "CASP9                                0\n",
       "CYLD                                 0\n",
       "ROBO2                                0\n",
       "ATP1A1                               0\n",
       "Length: 3684, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMiBbhagFpjFDqGyTxjkwri",
   "background_execution": "on",
   "machine_shape": "hm",
   "mount_file_id": "1Yw8v2kdGjDabUqdqOQx-hSxHg7-lqMur",
   "name": "DataPreparation_Drug_response_prediction.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-TF]",
   "language": "python",
   "name": "conda-env-.conda-TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
